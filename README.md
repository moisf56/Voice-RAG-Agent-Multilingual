# Multilingual Voice RAG Agent ğŸ™ï¸ğŸ¤–

A comprehensive voice-enabled AI assistant that combines speech-to-text, retrieval-augmented generation (RAG), and text-to-speech capabilities. Built with LangGraph, it supports multilingual conversations and maintains context across sessions while providing access to both web search and local knowledge bases.

## âœ¨ Features

- **ğŸ¤ Voice Input**: Real-time speech recognition using Google Cloud Speech-to-Text
- **ğŸ“š RAG Knowledge Base**: Local document search and retrieval using ChromaDB
- **ğŸ”Š Text-to-Speech**: High-quality voice synthesis with ElevenLabs
- **ğŸŒ Web Search**: Internet search capabilities via Tavily
- **ğŸ’¬ Memory Management**: Persistent conversation history with LangGraph
- **ğŸŒ Multilingual Support**: Arabic and English language processing
- **ğŸ”§ Modular Design**: Separate text-only and voice-enabled modes

## ğŸ—ï¸ Architecture

The system consists of three main components:

1. **RAG Chatbot** (`memoryrag.py`): Core chatbot with knowledge base integration
2. **Voice Interface** (`voice-rag.py`): Full voice conversation capabilities
3. **Knowledge Base**: ChromaDB vector store for document retrieval

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Google Cloud Speech-to-Text API credentials
- ElevenLabs API key (for TTS)
- vLLM server running Qwen2.5-32B-Instruct

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/multilingual-speech-agent.git
cd multilingual-speech-agent
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Set up environment variables**
```bash
export ELEVENLABS_API_KEY="your-elevenlabs-api-key"
export GOOGLE_APPLICATION_CREDENTIALS="path/to/your/gcp-credentials.json"
```

4. **Prepare knowledge base**
```bash
mkdir knowledge_base
# Add your PDF and TXT files to this directory
```

### Usage

#### Text-Only Mode
```bash
python memoryrag.py
```

#### Full Voice Mode
```bash
python voice-rag.py --language_code ar-SA --elevenlabs_key YOUR_KEY
```

#### Voice Commands
- **Arabic**: "Ø®Ø±ÙˆØ¬" or "ØªÙˆÙ‚Ù" to exit, "Ø¬Ø¯ÙŠØ¯" for new conversation
- **English**: "exit" or "quit" to stop, "new" for new conversation

## âš™ï¸ Configuration

### vLLM Server Configuration
```python
BASE_URL = "https://your-vllm-server:8000/v1"
MODEL = "Qwen/Qwen2.5-32B-Instruct"
```

### Speech Recognition Settings
- **Language**: Arabic (ar-SA) by default
- **Model**: Google Cloud Speech latest_long
- **Audio**: 16kHz, mono, LINEAR16

### TTS Configuration
- **Provider**: ElevenLabs
- **Model**: eleven_turbo_v2_5
- **Default Voice**: Adam (multilingual)

## ğŸ“ Project Structure

```
multilingual-speech-agent/
â”œâ”€â”€ memoryrag.py          # Core RAG chatbot
â”œâ”€â”€ voice-rag.py          # Voice interface
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ knowledge_base/       # Documents for RAG
â”œâ”€â”€ chroma_db_rag/       # Vector database
â”œâ”€â”€ API-Keys.txt         # API keys (gitignored)
â””â”€â”€ old/                 # Archive files
```

## ğŸ› ï¸ Development

### Adding Documents
Place PDF or TXT files in the `knowledge_base/` directory. The system automatically:
- Loads and chunks documents
- Creates embeddings using multilingual-e5-small
- Stores in persistent ChromaDB vector store

### Customizing the LLM
Modify the system prompt in `memoryrag.py` to adjust the assistant's behavior:

```python
SYSTEM_PROMPT = """You are a professional AI assistant..."""
```

## ğŸ”§ Troubleshooting

**Common Issues:**
- **No audio output**: Check ElevenLabs API key and voice ID
- **Speech not recognized**: Verify Google Cloud credentials
- **Empty knowledge base**: Ensure documents are in `knowledge_base/` folder
- **Connection errors**: Confirm vLLM server is running and accessible

## ğŸ“Š Performance

- **Response Time**: ~2-3 seconds for text queries
- **Voice Latency**: ~3-5 seconds end-to-end
- **Supported Languages**: Arabic, English (extensible)
- **Document Capacity**: Unlimited (ChromaDB scales)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Commit changes: `git commit -am 'Add feature'`
4. Push to branch: `git push origin feature-name`
5. Submit a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **LangChain/LangGraph**: Agent framework
- **Google Cloud Speech**: Speech recognition
- **ElevenLabs**: Text-to-speech synthesis
- **ChromaDB**: Vector database
- **Qwen2.5**: Language model capabilities

---

**Built with â¤ï¸ for multilingual AI conversations**
